{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ryukijano/Deep_reinforcement_learning_Course/blob/master/Copy_of_unit5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D3NL_e4crQv"
      },
      "source": [
        "# Unit 5: An Introduction to ML-Agents\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/thumbnail.png\" alt=\"Thumbnail\"/>\n",
        "\n",
        "In this notebook, you'll learn about ML-Agents and train two agents.\n",
        "\n",
        "- The first one will learn to **shoot snowballs onto spawning targets**.\n",
        "- The second need to press a button to spawn a pyramid, then navigate to the pyramid, knock it over, **and move to the gold brick at the top**. To do that, it will need to explore its environment, and we will use a technique called curiosity.\n",
        "\n",
        "After that, you'll be able **to watch your agents playing directly on your browser**.\n",
        "\n",
        "For more information about the certification process, check this section 👉 https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process"
      ],
      "metadata": {
        "id": "97ZiytXEgqIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⬇️ Here is an example of what **you will achieve at the end of this unit.** ⬇️\n"
      ],
      "metadata": {
        "id": "FMYrDriDujzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/pyramids.gif\" alt=\"Pyramids\"/>\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballtarget.gif\" alt=\"SnowballTarget\"/>"
      ],
      "metadata": {
        "id": "cBmFlh8suma-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🎮 Environments: \n",
        "\n",
        "- [Pyramids](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Learning-Environment-Examples.md#pyramids)\n",
        "- SnowballTarget\n",
        "\n",
        "### 📚 RL-Library: \n",
        "\n",
        "- [ML-Agents (HuggingFace Experimental Version)](https://github.com/huggingface/ml-agents)\n",
        "\n",
        "⚠ We're going to use an experimental version of ML-Agents were you can push to hub and load from hub Unity ML-Agents Models **you need to install the same version**"
      ],
      "metadata": {
        "id": "A-cYE0K5iL-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the GitHub Repo](https://github.com/huggingface/deep-rl-class/issues)."
      ],
      "metadata": {
        "id": "qEhtaFh9i31S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objectives of this notebook 🏆\n",
        "\n",
        "At the end of the notebook, you will:\n",
        "\n",
        "- Understand how works **ML-Agents**, the environment library.\n",
        "- Be able to **train agents in Unity Environments**.\n"
      ],
      "metadata": {
        "id": "j7f63r3Yi5vE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook is from the Deep Reinforcement Learning Course\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>"
      ],
      "metadata": {
        "id": "viNzVbVaYvY3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p5HnEefISCB"
      },
      "source": [
        "In this free course, you will:\n",
        "\n",
        "- 📖 Study Deep Reinforcement Learning in **theory and practice**.\n",
        "- 🧑‍💻 Learn to **use famous Deep RL libraries** such as Stable Baselines3, RL Baselines3 Zoo, CleanRL and Sample Factory 2.0.\n",
        "- 🤖 Train **agents in unique environments** \n",
        "\n",
        "And more check 📚 the syllabus 👉 https://huggingface.co/deep-rl-course/communication/publishing-schedule\n",
        "\n",
        "Don’t forget to **<a href=\"http://eepurl.com/ic5ZUD\">sign up to the course</a>** (we are collecting your email to be able to **send you the links when each Unit is published and give you information about the challenges and updates).**\n",
        "\n",
        "\n",
        "The best way to keep in touch is to join our discord server to exchange with the community and with us 👉🏻 https://discord.gg/ydHrjt3WP5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-mo_6rXIjRi"
      },
      "source": [
        "## Prerequisites 🏗️\n",
        "Before diving into the notebook, you need to:\n",
        "\n",
        "🔲 📚 **Study [what is ML-Agents and how it works by reading Unit 5](https://huggingface.co/deep-rl-course/unit5/introduction)**  🤗  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's train our agents 🚀\n",
        "\n",
        "The ML-Agents integration on the Hub is **still experimental**, some features will be added in the future. \n",
        "\n",
        "But for now, **to validate this hands-on for the certification process, you just need to push your trained models to the Hub**. There’s no results to attain to validate this one. But if you want to get nice results you can try to attain:\n",
        "\n",
        "- For `Pyramids` : Mean Reward = 1.75\n",
        "- For `SnowballTarget` : Mean Reward = 15 or 30 targets hit in an episode.\n"
      ],
      "metadata": {
        "id": "xYO1uD5Ujgdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the GPU 💪\n",
        "- To **accelerate the agent's training, we'll use a GPU**. To do that, go to `Runtime > Change Runtime type`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">"
      ],
      "metadata": {
        "id": "DssdIjk_8vZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `Hardware Accelerator > GPU`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">"
      ],
      "metadata": {
        "id": "sTfCXHy68xBv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an3ByrXYQ4iK"
      },
      "source": [
        "## Clone the repository and install the dependencies 🔽\n",
        "- We need to clone the repository, that **contains the experimental version of the library that allows you to push your trained agent to the Hub.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install --upgrade tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbiTeOlhtaPw",
        "outputId": "00b4ab4b-5d37-4690-97fe-bb879f900f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorrt\n",
            "  Downloading tensorrt-8.5.3.1-cp38-none-manylinux_2_17_x86_64.whl (549.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.5/549.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 KB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11\n",
            "  Downloading nvidia_cudnn_cu11-8.8.0.121-py3-none-manylinux1_x86_64.whl (720.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.3/720.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, tensorrt\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.8.0.121 tensorrt-8.5.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y --no-install-recommends libnvinfer=8.5.3.1-1+cuda11.8 \\\n",
        "  libnvinfer-dev=8.5.3.1-1+cuda11.8 \\\n",
        "  libnvinfer-plugin=8.5.3.1-1+cuda11.8\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwDQxDOjtlVR",
        "outputId": "96365c70-1422-442b-ba7b-9916eafcd19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package libnvinfer\n",
            "E: Version '8.5.3.1-1+cuda11.8' for 'libnvinfer-dev' was not found\n",
            "E: Unable to locate package libnvinfer-plugin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt\n",
        "print(tensorrt.__version__)\n",
        "assert tensorrt.Builder(tensorrt.Logger())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yj735T0w5Bb",
        "outputId": "52d8a447-511d-4911-861e-7eb28e2e2caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.5.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install numpy\n",
        "!sudo apt-get install python3-libnvinfer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drCfzgsfw7C5",
        "outputId": "59089079-6259-49f1-e934-37095e5ca533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.22.4)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libnvinfer-plugin8 libnvinfer8 libnvonnxparsers8 libnvparsers8\n",
            "The following NEW packages will be installed:\n",
            "  libnvinfer-plugin8 libnvinfer8 libnvonnxparsers8 libnvparsers8\n",
            "  python3-libnvinfer\n",
            "0 upgraded, 5 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 291 MB of archives.\n",
            "After this operation, 921 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libnvinfer8 8.5.3-1+cuda11.8 [274 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libnvinfer-plugin8 8.5.3-1+cuda11.8 [14.3 MB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libnvonnxparsers8 8.5.3-1+cuda11.8 [717 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libnvparsers8 8.5.3-1+cuda11.8 [804 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  python3-libnvinfer 8.5.3-1+cuda11.8 [621 kB]\n",
            "Fetched 291 MB in 6s (51.5 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libnvinfer8.\n",
            "(Reading database ... 128208 files and directories currently installed.)\n",
            "Preparing to unpack .../libnvinfer8_8.5.3-1+cuda11.8_amd64.deb ...\n",
            "Unpacking libnvinfer8 (8.5.3-1+cuda11.8) ...\n",
            "Selecting previously unselected package libnvinfer-plugin8.\n",
            "Preparing to unpack .../libnvinfer-plugin8_8.5.3-1+cuda11.8_amd64.deb ...\n",
            "Unpacking libnvinfer-plugin8 (8.5.3-1+cuda11.8) ...\n",
            "Selecting previously unselected package libnvonnxparsers8.\n",
            "Preparing to unpack .../libnvonnxparsers8_8.5.3-1+cuda11.8_amd64.deb ...\n",
            "Unpacking libnvonnxparsers8 (8.5.3-1+cuda11.8) ...\n",
            "Selecting previously unselected package libnvparsers8.\n",
            "Preparing to unpack .../libnvparsers8_8.5.3-1+cuda11.8_amd64.deb ...\n",
            "Unpacking libnvparsers8 (8.5.3-1+cuda11.8) ...\n",
            "Selecting previously unselected package python3-libnvinfer.\n",
            "Preparing to unpack .../python3-libnvinfer_8.5.3-1+cuda11.8_amd64.deb ...\n",
            "Unpacking python3-libnvinfer (8.5.3-1+cuda11.8) ...\n",
            "Setting up libnvinfer8 (8.5.3-1+cuda11.8) ...\n",
            "Setting up libnvparsers8 (8.5.3-1+cuda11.8) ...\n",
            "Setting up libnvinfer-plugin8 (8.5.3-1+cuda11.8) ...\n",
            "Setting up libnvonnxparsers8 (8.5.3-1+cuda11.8) ...\n",
            "Setting up python3-libnvinfer (8.5.3-1+cuda11.8) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt\n",
        "print(tensorrt.__version__)\n",
        "assert tensorrt.Builder(tensorrt.Logger())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw2wzIUvxF3g",
        "outputId": "3b7bc6f2-0724-4ce9-9e95-2bda79fdf9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.5.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WNoL04M7rTa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Clone the repository\n",
        "!git clone --depth 1 https://github.com/huggingface/ml-agents/ "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoR8i-MwuNDC",
        "outputId": "7154a1af-8de8-4c04-da79-25d7a7841646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.5.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8wmVcMk7xKo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Go inside the repository and install the package\n",
        "%cd ml-agents\n",
        "!pip3 install -e ./ml-agents-envs\n",
        "!pip3 install -e ./ml-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRd6HmY-uffY",
        "outputId": "0a8b39a0-fc3d-42f6-a33b-f8b24df78253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.22.4)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libnvinfer-plugin8 libnvinfer8 libnvonnxparsers8 libnvparsers8\n",
            "The following NEW packages will be installed:\n",
            "  libnvinfer-plugin8 libnvinfer8 libnvonnxparsers8 libnvparsers8\n",
            "  python3-libnvinfer\n",
            "0 upgraded, 5 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 291 MB of archives.\n",
            "After this operation, 921 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libnvinfer8 8.5.3-1+cuda11.8 [274 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libnvinfer-plugin8 8.5.3-1+cuda11.8 [14.3 MB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libnvonnxparsers8 8.5.3-1+cuda11.8 [717 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libnvparsers8 8.5.3-1+cuda11.8 [804 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  python3-libnvinfer 8.5.3-1+cuda11.8 [621 kB]\n",
            "Fetched 291 MB in 4s (72.7 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libnvinfer8.\n",
            "(Reading database ... 128208 files and directories currently installed.)\n",
            "Preparing to unpack .../libnvinfer8_8.5.3-1+cuda11.8_amd64.deb ...\n",
            "Unpacking libnvinfer8 (8.5.3-1+cuda11.8) ...\n",
            "Selecting previously unselected package libnvinfer-plugin8.\n",
            "Preparing to unpack .../libnvinfer-plugin8_8.5.3-1+cuda11.8_amd64.deb ...\n",
            "Unpacking libnvinfer-plugin8 (8.5.3-1+cuda11.8) ...\n",
            "Selecting previously unselected package libnvonnxparsers8.\n",
            "Preparing to unpack .../libnvonnxparsers8_8.5.3-1+cuda11.8_amd64.deb ...\n",
            "Unpacking libnvonnxparsers8 (8.5.3-1+cuda11.8) ...\n",
            "Selecting previously unselected package libnvparsers8.\n",
            "Preparing to unpack .../libnvparsers8_8.5.3-1+cuda11.8_amd64.deb ...\n",
            "Unpacking libnvparsers8 (8.5.3-1+cuda11.8) ...\n",
            "Selecting previously unselected package python3-libnvinfer.\n",
            "Preparing to unpack .../python3-libnvinfer_8.5.3-1+cuda11.8_amd64.deb ...\n",
            "Unpacking python3-libnvinfer (8.5.3-1+cuda11.8) ...\n",
            "Setting up libnvinfer8 (8.5.3-1+cuda11.8) ...\n",
            "Setting up libnvparsers8 (8.5.3-1+cuda11.8) ...\n",
            "Setting up libnvinfer-plugin8 (8.5.3-1+cuda11.8) ...\n",
            "Setting up libnvonnxparsers8 (8.5.3-1+cuda11.8) ...\n",
            "Setting up python3-libnvinfer (8.5.3-1+cuda11.8) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-mark unhold tensorrt-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQroLsCPut7F",
        "outputId": "5c8a6530-d97b-4cbc-d27e-544449fb5ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorrt-dev was already not hold.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SnowballTarget ⛄\n",
        "\n",
        "If you need a refresher on how this environments work check this section 👉\n",
        "https://huggingface.co/deep-rl-course/unit5/snowball-target"
      ],
      "metadata": {
        "id": "R5_7Ptd_kEcG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRY5ufKUKfhI"
      },
      "source": [
        "### Download and move the environment zip file in `./training-envs-executables/linux/`\n",
        "- Our environment executable is in a zip file.\n",
        "- We need to download it and place it to `./training-envs-executables/linux/`\n",
        "- We use a linux executable because we use colab, and colab machines OS is Ubuntu (linux)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9Ls6_6eOKiA"
      },
      "outputs": [],
      "source": [
        "# Here, we create training-envs-executables and linux\n",
        "!mkdir ./training-envs-executables\n",
        "!mkdir ./training-envs-executables/linux"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsoZGxr1MIXY"
      },
      "source": [
        "Download the file SnowballTarget.zip from https://drive.google.com/file/d/1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5 using `wget`. \n",
        "\n",
        "Check out the full solution to download large files from GDrive [here](https://bcrf.biochem.wisc.edu/2021/02/05/download-google-drive-files-using-wget/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU6gi8CmWhnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1594afe0-1634-405e-db41-6c3ec8c4f683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-26 07:44:44--  https://docs.google.com/uc?export=download&confirm=t&id=1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.119.100, 108.177.119.101, 108.177.119.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.119.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-14-28-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ed7othofeqs8pnc62elmtghvjtpna1vo/1677397425000/15803371278684422230/*/1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5?e=download&uuid=3842b49f-a449-466a-82bb-fa16b2bcab6d [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-02-26 07:44:45--  https://doc-14-28-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ed7othofeqs8pnc62elmtghvjtpna1vo/1677397425000/15803371278684422230/*/1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5?e=download&uuid=3842b49f-a449-466a-82bb-fa16b2bcab6d\n",
            "Resolving doc-14-28-docs.googleusercontent.com (doc-14-28-docs.googleusercontent.com)... 173.194.79.132, 2a00:1450:4013:c05::84\n",
            "Connecting to doc-14-28-docs.googleusercontent.com (doc-14-28-docs.googleusercontent.com)|173.194.79.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35134213 (34M) [application/x-zip-compressed]\n",
            "Saving to: ‘./training-envs-executables/linux/SnowballTarget.zip’\n",
            "\n",
            "./training-envs-exe 100%[===================>]  33.51M   128MB/s    in 0.3s    \n",
            "\n",
            "2023-02-26 07:44:45 (128 MB/s) - ‘./training-envs-executables/linux/SnowballTarget.zip’ saved [35134213/35134213]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5\" -O ./training-envs-executables/linux/SnowballTarget.zip && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We unzip the executable.zip file"
      ],
      "metadata": {
        "id": "_LLVaEEK3ayi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FPx0an9IAwO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/SnowballTarget.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyumV5XfPKzu"
      },
      "source": [
        "Make sure your file is accessible "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdFsLJ11JvQf"
      },
      "outputs": [],
      "source": [
        "!chmod -R 755 ./training-envs-executables/linux/SnowballTarget"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the SnowballTarget config file\n",
        "- In ML-Agents, you define the **training hyperparameters into config.yaml files.**\n",
        "\n",
        "There are multiple hyperparameters. To know them better, you should check for each explanation with [the documentation](https://github.com/Unity-Technologies/ml-agents/blob/release_20_docs/docs/Training-Configuration-File.md)\n",
        "\n",
        "\n",
        "So you need to create a `SnowballTarget.yaml` config file in ./content/ml-agents/config/ppo/\n",
        "\n",
        "We'll give you here a first version of this config (to copy and paste into your `SnowballTarget.yaml file`), **but you should modify it**.\n",
        "\n",
        "```\n",
        "behaviors:\n",
        "  SnowballTarget:\n",
        "    trainer_type: ppo\n",
        "    summary_freq: 10000\n",
        "    keep_checkpoints: 10\n",
        "    checkpoint_interval: 50000\n",
        "    max_steps: 200000\n",
        "    time_horizon: 64\n",
        "    threaded: true\n",
        "    hyperparameters:\n",
        "      learning_rate: 0.0003\n",
        "      learning_rate_schedule: linear\n",
        "      batch_size: 128\n",
        "      buffer_size: 2048\n",
        "      beta: 0.005\n",
        "      epsilon: 0.2\n",
        "      lambd: 0.95\n",
        "      num_epoch: 3\n",
        "    network_settings:\n",
        "      normalize: false\n",
        "      hidden_units: 256\n",
        "      num_layers: 2\n",
        "      vis_encode_type: simple\n",
        "    reward_signals:\n",
        "      extrinsic:\n",
        "        gamma: 0.99\n",
        "        strength: 1.0\n",
        "```"
      ],
      "metadata": {
        "id": "NAuEq32Mwvtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballfight_config1.png\" alt=\"Config SnowballTarget\"/>\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballfight_config2.png\" alt=\"Config SnowballTarget\"/>"
      ],
      "metadata": {
        "id": "4U3sRH4N4h_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As an experimentation, you should also try to modify some other hyperparameters. Unity provides very [good documentation explaining each of them here](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md).\n",
        "\n",
        "Now that you've created the config file and understand what most hyperparameters do, we're ready to train our agent 🔥."
      ],
      "metadata": {
        "id": "JJJdo_5AyoGo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9fI555bO12v"
      },
      "source": [
        "### Train the agent\n",
        "\n",
        "To train our agent, we just need to **launch mlagents-learn and select the executable containing the environment.**\n",
        "\n",
        "We define four parameters:\n",
        "\n",
        "1. `mlagents-learn <config>`: the path where the hyperparameter config file is.\n",
        "2. `--env`: where the environment executable is.\n",
        "3. `--run_id`: the name you want to give to your training run id.\n",
        "4. `--no-graphics`: to not launch the visualization during the training.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/mlagentslearn.png\" alt=\"MlAgents learn\"/>\n",
        "\n",
        "Train the model and use the `--resume` flag to continue training in case of interruption. \n",
        "\n",
        "> It will fail first time if and when you use `--resume`, try running the block again to bypass the error. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training will take 10 to 35min depending on your config, go take a ☕️you deserve it 🤗."
      ],
      "metadata": {
        "id": "lN32oWF8zPjs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS-Yh1UdHfzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c882d9f7-6fa4-434f-dbdd-2913a8b43444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            ┐  ╖\n",
            "        ╓╖╬│╡  ││╬╖╖\n",
            "    ╓╖╬│││││┘  ╬│││││╬╖\n",
            " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
            " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
            " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
            " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
            " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
            " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
            " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
            "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
            "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
            "          ╙╬╬╬╣╣╣╜\n",
            "             ╙\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 0.29.0.dev0,\n",
            "  ml-agents-envs: 0.29.0.dev0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 1.8.1+cu102\n",
            "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
            "[INFO] Connected new brain: SnowballTarget?team=0\n",
            "[WARNING] Deleting TensorBoard data events.out.tfevents.1677332536.ac74cbd175f7.3891.0 that was left over from a previous run.\n",
            "2023-02-25 14:07:34.284490: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-25 14:07:35.164479: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-25 14:07:35.164588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-25 14:07:35.164607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[INFO] Hyperparameters for behavior name SnowballTarget: \n",
            "\ttrainer_type:\tppo\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t512\n",
            "\t  buffer_size:\t409600\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.005\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t10\n",
            "\t  learning_rate_schedule:\tlinear\n",
            "\t  beta_schedule:\tlinear\n",
            "\t  epsilon_schedule:\tlinear\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t3\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t10\n",
            "\tcheckpoint_interval:\t50000\n",
            "\tmax_steps:\t200000\n",
            "\ttime_horizon:\t64\n",
            "\tsummary_freq:\t10000\n",
            "\tthreaded:\tTrue\n",
            "\tself_play:\tNone\n",
            "\tbehavioral_cloning:\tNone\n",
            "INFO:mlagents.trainers.stats:Hyperparameters for behavior name SnowballTarget: \n",
            "\ttrainer_type:\tppo\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t512\n",
            "\t  buffer_size:\t409600\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.005\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t10\n",
            "\t  learning_rate_schedule:\tlinear\n",
            "\t  beta_schedule:\tlinear\n",
            "\t  epsilon_schedule:\tlinear\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t3\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t10\n",
            "\tcheckpoint_interval:\t50000\n",
            "\tmax_steps:\t200000\n",
            "\ttime_horizon:\t64\n",
            "\tsummary_freq:\t10000\n",
            "\tthreaded:\tTrue\n",
            "\tself_play:\tNone\n",
            "\tbehavioral_cloning:\tNone\n",
            "[INFO] SnowballTarget. Step: 10000. Time Elapsed: 26.383 s. Mean Reward: 3.455. Std of Reward: 1.712. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 10000. Time Elapsed: 26.383 s. Mean Reward: 3.455. Std of Reward: 1.712. Training.\n",
            "[INFO] SnowballTarget. Step: 20000. Time Elapsed: 46.004 s. Mean Reward: 3.036. Std of Reward: 1.926. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 20000. Time Elapsed: 46.004 s. Mean Reward: 3.036. Std of Reward: 1.926. Training.\n",
            "[INFO] SnowballTarget. Step: 30000. Time Elapsed: 66.307 s. Mean Reward: 2.591. Std of Reward: 1.656. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 30000. Time Elapsed: 66.307 s. Mean Reward: 2.591. Std of Reward: 1.656. Training.\n",
            "[INFO] SnowballTarget. Step: 40000. Time Elapsed: 85.745 s. Mean Reward: 3.145. Std of Reward: 1.949. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 40000. Time Elapsed: 85.745 s. Mean Reward: 3.145. Std of Reward: 1.949. Training.\n",
            "[INFO] SnowballTarget. Step: 50000. Time Elapsed: 105.473 s. Mean Reward: 2.955. Std of Reward: 1.665. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 50000. Time Elapsed: 105.473 s. Mean Reward: 2.955. Std of Reward: 1.665. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-49936.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-49936.onnx\n",
            "[INFO] SnowballTarget. Step: 60000. Time Elapsed: 123.850 s. Mean Reward: 2.727. Std of Reward: 1.783. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 60000. Time Elapsed: 123.850 s. Mean Reward: 2.727. Std of Reward: 1.783. Training.\n",
            "[INFO] SnowballTarget. Step: 70000. Time Elapsed: 143.002 s. Mean Reward: 2.455. Std of Reward: 1.588. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 70000. Time Elapsed: 143.002 s. Mean Reward: 2.455. Std of Reward: 1.588. Training.\n",
            "[INFO] SnowballTarget. Step: 80000. Time Elapsed: 163.246 s. Mean Reward: 2.345. Std of Reward: 1.296. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 80000. Time Elapsed: 163.246 s. Mean Reward: 2.345. Std of Reward: 1.296. Training.\n",
            "[INFO] SnowballTarget. Step: 90000. Time Elapsed: 181.267 s. Mean Reward: 2.705. Std of Reward: 1.501. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 90000. Time Elapsed: 181.267 s. Mean Reward: 2.705. Std of Reward: 1.501. Training.\n",
            "[INFO] SnowballTarget. Step: 100000. Time Elapsed: 201.514 s. Mean Reward: 2.873. Std of Reward: 2.107. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 100000. Time Elapsed: 201.514 s. Mean Reward: 2.873. Std of Reward: 2.107. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-99960.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-99960.onnx\n",
            "[INFO] SnowballTarget. Step: 110000. Time Elapsed: 220.628 s. Mean Reward: 2.704. Std of Reward: 1.921. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 110000. Time Elapsed: 220.628 s. Mean Reward: 2.704. Std of Reward: 1.921. Training.\n",
            "[INFO] SnowballTarget. Step: 120000. Time Elapsed: 239.770 s. Mean Reward: 2.556. Std of Reward: 1.720. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 120000. Time Elapsed: 239.770 s. Mean Reward: 2.556. Std of Reward: 1.720. Training.\n",
            "[INFO] SnowballTarget. Step: 130000. Time Elapsed: 261.295 s. Mean Reward: 2.473. Std of Reward: 1.683. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 130000. Time Elapsed: 261.295 s. Mean Reward: 2.473. Std of Reward: 1.683. Training.\n",
            "[INFO] SnowballTarget. Step: 140000. Time Elapsed: 279.548 s. Mean Reward: 3.205. Std of Reward: 1.853. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 140000. Time Elapsed: 279.548 s. Mean Reward: 3.205. Std of Reward: 1.853. Training.\n",
            "[INFO] SnowballTarget. Step: 150000. Time Elapsed: 299.458 s. Mean Reward: 2.782. Std of Reward: 1.942. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 150000. Time Elapsed: 299.458 s. Mean Reward: 2.782. Std of Reward: 1.942. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-149984.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-149984.onnx\n",
            "[INFO] SnowballTarget. Step: 160000. Time Elapsed: 319.080 s. Mean Reward: 2.682. Std of Reward: 1.648. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 160000. Time Elapsed: 319.080 s. Mean Reward: 2.682. Std of Reward: 1.648. Training.\n",
            "[INFO] SnowballTarget. Step: 170000. Time Elapsed: 336.963 s. Mean Reward: 2.582. Std of Reward: 1.745. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 170000. Time Elapsed: 336.963 s. Mean Reward: 2.582. Std of Reward: 1.745. Training.\n",
            "[INFO] SnowballTarget. Step: 180000. Time Elapsed: 357.038 s. Mean Reward: 2.455. Std of Reward: 1.738. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 180000. Time Elapsed: 357.038 s. Mean Reward: 2.455. Std of Reward: 1.738. Training.\n",
            "[INFO] SnowballTarget. Step: 190000. Time Elapsed: 376.990 s. Mean Reward: 2.709. Std of Reward: 1.846. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 190000. Time Elapsed: 376.990 s. Mean Reward: 2.709. Std of Reward: 1.846. Training.\n",
            "[INFO] SnowballTarget. Step: 200000. Time Elapsed: 394.991 s. Mean Reward: 2.864. Std of Reward: 2.074. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 200000. Time Elapsed: 394.991 s. Mean Reward: 2.864. Std of Reward: 2.074. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-199984.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-199984.onnx\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-200112.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-200112.onnx\n",
            "[INFO] Copied results/SnowballTarget1/SnowballTarget/SnowballTarget-200112.onnx to results/SnowballTarget1/SnowballTarget.onnx.\n",
            "INFO:mlagents.trainers.model_saver.torch_model_saver:Copied results/SnowballTarget1/SnowballTarget/SnowballTarget-200112.onnx to results/SnowballTarget1/SnowballTarget.onnx.\n"
          ]
        }
      ],
      "source": [
        "!mlagents-learn ./config/ppo/SnowballTarget.yaml --env=./training-envs-executables/linux/SnowballTarget/SnowballTarget --run-id=\"SnowballTarget1\" --no-graphics --force"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vue94AzPy1t"
      },
      "source": [
        "### Push the agent to the 🤗 Hub\n",
        "\n",
        "- Now that we trained our agent, we’re **ready to push it to the Hub to be able to visualize it playing on your browser🔥.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be able to share your model with the community there are three more steps to follow:\n",
        "\n",
        "1️⃣ (If it's not already done) create an account to HF ➡ https://huggingface.co/join\n",
        "\n",
        "2️⃣ Sign in and then, you need to store your authentication token from the Hugging Face website.\n",
        "- Create a new token (https://huggingface.co/settings/tokens) **with write role**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">\n",
        "\n",
        "- Copy the token \n",
        "- Run the cell below and paste the token"
      ],
      "metadata": {
        "id": "izT6FpgNzZ6R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKt2vsYoK56o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "b41fa3e4f1704166a2418f2c8ef0bc6e",
            "f718196e242a4648bdccf4080024ff69",
            "8e7c289afa6b492aa0f05b9c01e4c596",
            "960e7acc7aac4b58a9b9979a38001e6d",
            "f113bad6ac9a470aa4538197b8933245",
            "25df7f2224aa4499a217c54d72da606e",
            "b07921d954f440bfa0710286b0ca84ac",
            "6cb89755e2f741c19effa090b0ca9a92",
            "06e92b3251bc41af9642a427752e9b0c",
            "f53eaab2827348ccb8ee0bddc2f5d0a3",
            "1fa0a6d36d63400cb24d520791285888",
            "9bf362f578d34421ba4294119e26d162",
            "23c9d967006b460a864e53f0068fde1c",
            "d4ace146c29e4fe0ad8ab1fa747dddb0",
            "3d2ade4ac3cf441aa5b11c207d40d433",
            "b874a4b90e614c58b7ef88d28bc1ac1a",
            "1fe698303e3f4d548dfe7d501e2aa0a7"
          ]
        },
        "outputId": "cff4bf83-c783-47c6-f969-a2317dc4db2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid.\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command instead: `huggingface-cli login`"
      ],
      "metadata": {
        "id": "aSU9qD9_6dem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we simply need to run `mlagents-push-to-hf`.\n",
        "\n",
        "And we define 4 parameters:\n",
        "\n",
        "1. `--run-id`: the name of the training run id.\n",
        "2. `--local-dir`: where the agent was saved, it’s results/<run_id name>, so in my case results/First Training.\n",
        "3. `--repo-id`: the name of the Hugging Face repo you want to create or update. It’s always <your huggingface username>/<the repo name>\n",
        "If the repo does not exist **it will be created automatically**\n",
        "4. `--commit-message`: since HF repos are git repository you need to define a commit message.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/mlagentspushtohub.png\" alt=\"Push to Hub\"/>\n",
        "\n",
        "For instance:\n",
        "\n",
        "`!mlagents-push-to-hf  --run-id=\"SnowballTarget1\" --local-dir=\"./results/SnowballTarget1\" --repo-id=\"ThomasSimonini/ppo-SnowballTarget\"  --commit-message=\"First Push\"`"
      ],
      "metadata": {
        "id": "KK4fPfnczunT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGEFAIboLVc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97fe41da-46fe-420c-b987-763804281f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SnowballTarget_smoll\n",
            "Ryukijano/ppo-SnowballTarget\n",
            "This function will create a model card and upload your SnowballTarget_smoll into HuggingFace Hub. This is a work in progress: If you encounter a bug, please send open an issue\n",
            "REPO NAME:  ppo-SnowballTarget\n",
            "ORGANIZATION:  Ryukijano\n",
            "Cloning https://huggingface.co/Ryukijano/ppo-SnowballTarget into local empty directory.\n",
            "Upload file SnowballTarget/SnowballTarget-499976.pt:   0% 32.0k/16.3M [00:00<?, ?B/s]\n",
            "Upload file SnowballTarget/SnowballTarget-539704.pt:   0% 32.0k/16.3M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-449952.pt:   0% 32.0k/16.3M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-299968.pt:   1% 32.0k/5.45M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-149984.pt:   1% 32.0k/5.45M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-349992.pt:   1% 32.0k/5.45M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-249944.pt:   1% 32.0k/5.45M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-399992.pt:   1% 32.0k/5.45M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-449952.pt:   1% 160k/16.3M [00:01<02:09, 131kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-149984.pt:   3% 160k/5.45M [00:01<00:42, 131kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-299968.pt:   3% 160k/5.45M [00:01<00:42, 130kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-349992.pt:   3% 160k/5.45M [00:01<00:42, 130kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-499976.pt:   3% 448k/16.3M [00:01<00:39, 423kB/s]\n",
            "Upload file SnowballTarget/SnowballTarget-539704.pt:   1% 160k/16.3M [00:01<02:10, 130kB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-249944.pt:   3% 160k/5.45M [00:01<00:42, 130kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-299968.pt:  17% 960k/5.45M [00:02<00:08, 533kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-449952.pt:   6% 960k/16.3M [00:02<00:30, 533kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-249944.pt:  19% 1.03M/5.45M [00:02<00:07, 591kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Upload file SnowballTarget/SnowballTarget-539704.pt:   7% 1.16M/16.3M [00:02<00:23, 667kB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-499976.pt:  30% 4.84M/16.3M [00:02<00:04, 2.88MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-349992.pt:  18% 992k/5.45M [00:02<00:08, 552kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-399992.pt:  16% 896k/5.45M [00:02<00:09, 495kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-399992.pt:  84% 4.56M/5.45M [00:03<00:00, 2.03MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-449952.pt:  29% 4.81M/16.3M [00:03<00:05, 2.14MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-149984.pt:  87% 4.75M/5.45M [00:03<00:00, 2.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-249944.pt:  88% 4.78M/5.45M [00:03<00:00, 2.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-349992.pt:  87% 4.75M/5.45M [00:03<00:00, 2.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Upload file SnowballTarget/SnowballTarget-539704.pt:  30% 4.88M/16.3M [00:03<00:05, 2.13MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-499976.pt:  55% 8.91M/16.3M [00:03<00:02, 3.50MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-199984.pt:   1% 32.0k/5.45M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-200112.pt:   1% 32.0k/5.45M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-99960.pt:   1% 32.0k/5.45M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Upload file SnowballTarget/SnowballTarget-539704.pt:  57% 9.25M/16.3M [00:04<00:02, 3.09MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-199984.pt:  12% 672k/5.45M [00:01<00:07, 654kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-449952.pt:  57% 9.31M/16.3M [00:04<00:02, 3.14MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-499976.pt:  81% 13.2M/16.3M [00:04<00:00, 3.88MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-99960.pt:   7% 384k/5.45M [00:01<00:14, 360kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-49936.pt:   1% 32.0k/5.45M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget.onnx:   1% 32.0k/2.73M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-200112.pt:  80% 4.38M/5.45M [00:02<00:00, 2.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-199984.pt:  81% 4.44M/5.45M [00:02<00:00, 2.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Upload file SnowballTarget/SnowballTarget-539704.pt:  80% 13.1M/16.3M [00:05<00:00, 3.42MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-99960.pt:  75% 4.06M/5.45M [00:02<00:00, 2.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-449952.pt:  80% 13.1M/16.3M [00:05<00:00, 3.43MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-49936.pt:   4% 224k/5.45M [00:01<00:27, 196kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget.onnx:   8% 224k/2.73M [00:01<00:13, 196kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-449952.onnx:   1% 32.0k/2.73M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-249944.onnx:   1% 32.0k/2.73M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/events.out.tfevents.1677334056.ac74cbd175f7.10309.0:  31% 32.0k/103k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-449952.onnx:  40% 1.09M/2.73M [00:01<00:01, 1.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-249944.onnx:  15% 416k/2.73M [00:01<00:06, 393kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-49936.pt:  23% 1.25M/5.45M [00:02<00:06, 714kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget.onnx:  30% 832k/2.73M [00:02<00:04, 446kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[Aremote: Scanning LFS files for validity...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Ryukijano/ppo-SnowballTarget\n",
            "   f16ffdf..94ef248  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:remote: Scanning LFS files for validity...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Ryukijano/ppo-SnowballTarget\n",
            "   f16ffdf..94ef248  main -> main\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-499976.pt: 100% 16.3M/16.3M [00:08<00:00, 2.13MB/s]\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-539704.pt: 100% 16.3M/16.3M [00:08<00:00, 2.03MB/s]\u001b[A\n",
            "Upload file SnowballTarget/SnowballTarget-539704.pt: 100% 16.3M/16.3M [00:08<00:00, 2.13MB/s]\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-449952.pt: 100% 16.3M/16.3M [00:08<00:00, 2.03MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-449952.pt: 100% 16.3M/16.3M [00:08<00:00, 2.13MB/s]\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-299968.pt: 100% 5.45M/5.45M [00:08<00:00, 606kB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-299968.pt: 100% 5.45M/5.45M [00:08<00:00, 707kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-149984.pt: 100% 5.45M/5.45M [00:08<00:00, 607kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-149984.pt: 100% 5.45M/5.45M [00:08<00:00, 707kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-349992.pt: 100% 5.45M/5.45M [00:08<00:00, 605kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-349992.pt: 100% 5.45M/5.45M [00:08<00:00, 707kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-249944.pt: 100% 5.45M/5.45M [00:08<00:00, 601kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-249944.pt: 100% 5.45M/5.45M [00:08<00:00, 707kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-399992.pt: 100% 5.45M/5.45M [00:08<00:00, 617kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-399992.pt: 100% 5.45M/5.45M [00:08<00:00, 707kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-199984.pt: 100% 5.45M/5.45M [00:05<00:00, 988kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-199984.pt: 100% 5.45M/5.45M [00:05<00:00, 1.13MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-200112.pt: 100% 5.45M/5.45M [00:05<00:00, 991kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-200112.pt: 100% 5.45M/5.45M [00:05<00:00, 1.13MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-99960.pt: 100% 5.45M/5.45M [00:05<00:00, 1.03MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-99960.pt: 100% 5.45M/5.45M [00:05<00:00, 1.13MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-49936.pt: 100% 5.45M/5.45M [00:04<00:00, 1.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-49936.pt: 100% 5.45M/5.45M [00:04<00:00, 1.42MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget.onnx: 100% 2.73M/2.73M [00:04<00:00, 794kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget.onnx: 100% 2.73M/2.73M [00:04<00:00, 705kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-449952.onnx: 100% 2.73M/2.73M [00:03<00:00, 921kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-449952.onnx: 100% 2.73M/2.73M [00:03<00:00, 940kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-249944.onnx: 100% 2.73M/2.73M [00:03<00:00, 1.00MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/SnowballTarget-249944.onnx: 100% 2.73M/2.73M [00:03<00:00, 940kB/s] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/events.out.tfevents.1677334056.ac74cbd175f7.10309.0: 100% 103k/103k [00:03<00:00, 24.1kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file SnowballTarget/events.out.tfevents.1677334056.ac74cbd175f7.10309.0: 100% 103k/103k [00:03<00:00, 24.1kB/s]\n",
            "\n",
            " Your model is pushed to the hub. You can view your model here: https://huggingface.co/Ryukijano/ppo-SnowballTarget\n"
          ]
        }
      ],
      "source": [
        "!mlagents-push-to-hf --run-id=\"SnowballTarget_smoll\" --local-dir=\"./results/SnowballTarget1\" --repo-id=\"Ryukijano/ppo-SnowballTarget\" --commit-message=\"First Push\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Else, if everything worked you should have this at the end of the process(but with a different url 😆) :\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Your model is pushed to the hub. You can view your model here: https://huggingface.co/ThomasSimonini/ppo-SnowballTarget\n",
        "```\n",
        "\n",
        "It’s the link to your model, it contains a model card that explains how to use it, your Tensorboard and your config file. **What’s awesome is that it’s a git repository, that means you can have different commits, update your repository with a new push etc.**"
      ],
      "metadata": {
        "id": "yborB0850FTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But now comes the best: **being able to visualize your agent online 👀.**"
      ],
      "metadata": {
        "id": "5Uaon2cg0NrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Watch your agent playing 👀\n",
        "\n",
        "For this step it’s simple:\n",
        "\n",
        "1. Remember your repo-id\n",
        "\n",
        "2. Go here: https://singularite.itch.io/snowballtarget\n",
        "\n",
        "3. Launch the game and put it in full screen by clicking on the bottom right button\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballtarget_load.png\" alt=\"Snowballtarget load\"/>"
      ],
      "metadata": {
        "id": "VMc4oOsE0QiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. In step 1, choose your model repository which is the model id (in my case ThomasSimonini/ppo-SnowballTarget).\n",
        "\n",
        "2. In step 2, **choose what model you want to replay**:\n",
        "  - I have multiple one, since we saved a model every 500000 timesteps. \n",
        "  - But if I want the more recent I choose `SnowballTarget.onnx`\n",
        "\n",
        "👉 What’s nice **is to try with different models step to see the improvement of the agent.**\n",
        "\n",
        "And don't hesitate to share the best score your agent gets on discord in #rl-i-made-this channel 🔥\n",
        "\n",
        "Let's now try a harder environment called Pyramids..."
      ],
      "metadata": {
        "id": "Djs8c5rR0Z8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pyramids 🏆\n",
        "\n",
        "### Download and move the environment zip file in `./training-envs-executables/linux/`\n",
        "- Our environment executable is in a zip file.\n",
        "- We need to download it and place it to `./training-envs-executables/linux/`\n",
        "- We use a linux executable because we use colab, and colab machines OS is Ubuntu (linux)"
      ],
      "metadata": {
        "id": "rVMwRi4y_tmx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyqYYkLyAVMK"
      },
      "source": [
        "Download the file Pyramids.zip from https://drive.google.com/uc?export=download&id=1UiFNdKlsH0NTu32xV-giYUEVKV4-vc7H using `wget`. Check out the full solution to download large files from GDrive [here](https://bcrf.biochem.wisc.edu/2021/02/05/download-google-drive-files-using-wget/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxojCsSVAVMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59f0c1e-9981-4f35-9538-15889b3474d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-26 07:45:42--  https://docs.google.com/uc?export=download&confirm=t&id=1UiFNdKlsH0NTu32xV-giYUEVKV4-vc7H\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.119.139, 108.177.119.138, 108.177.119.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.119.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-8c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ohp15q44o18i9qltm6u954361jsh07ma/1677397500000/09764732090272539193/*/1UiFNdKlsH0NTu32xV-giYUEVKV4-vc7H?e=download&uuid=84d1012a-2937-42b5-a115-d3ac9ac185a4 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-02-26 07:45:43--  https://doc-04-8c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ohp15q44o18i9qltm6u954361jsh07ma/1677397500000/09764732090272539193/*/1UiFNdKlsH0NTu32xV-giYUEVKV4-vc7H?e=download&uuid=84d1012a-2937-42b5-a115-d3ac9ac185a4\n",
            "Resolving doc-04-8c-docs.googleusercontent.com (doc-04-8c-docs.googleusercontent.com)... 173.194.79.132, 2a00:1450:4013:c05::84\n",
            "Connecting to doc-04-8c-docs.googleusercontent.com (doc-04-8c-docs.googleusercontent.com)|173.194.79.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42907187 (41M) [application/zip]\n",
            "Saving to: ‘./training-envs-executables/linux/Pyramids.zip’\n",
            "\n",
            "./training-envs-exe 100%[===================>]  40.92M   117MB/s    in 0.3s    \n",
            "\n",
            "2023-02-26 07:45:44 (117 MB/s) - ‘./training-envs-executables/linux/Pyramids.zip’ saved [42907187/42907187]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UiFNdKlsH0NTu32xV-giYUEVKV4-vc7H' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1UiFNdKlsH0NTu32xV-giYUEVKV4-vc7H\" -O ./training-envs-executables/linux/Pyramids.zip && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfs6CTJ1AVMP"
      },
      "source": [
        "**OR** Download directly to local machine and then drag and drop the file from local machine to `./training-envs-executables/linux`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7JmgOwcSSmF"
      },
      "source": [
        "Wait for the upload to finish and then run the command below. \n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip it"
      ],
      "metadata": {
        "id": "iWUUcs0_794U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2E3K4V2AVMP"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/Pyramids.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmKYBgHTAVMP"
      },
      "source": [
        "Make sure your file is accessible "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im-nwvLPAVMP"
      },
      "outputs": [],
      "source": [
        "!chmod -R 755 ./training-envs-executables/linux/Pyramids/Pyramids"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Modify the PyramidsRND config file\n",
        "- Contrary to the first environment which was a custom one, **Pyramids was made by the Unity team**.\n",
        "- So the PyramidsRND config file already exists and is in ./content/ml-agents/config/ppo/PyramidsRND.yaml\n",
        "- You might asked why \"RND\" in PyramidsRND. RND stands for *random network distillation* it's a way to generate curiosity rewards. If you want to know more on that we wrote an article explaning this technique: https://medium.com/data-from-the-trenches/curiosity-driven-learning-through-random-network-distillation-488ffd8e5938\n",
        "\n",
        "For this training, we’ll modify one thing:\n",
        "- The total training steps hyperparameter is too high since we can hit the benchmark (mean reward = 1.75) in only 1M training steps.\n",
        "👉 To do that, we go to config/ppo/PyramidsRND.yaml,**and modify these to max_steps to 1000000.**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/pyramids-config.png\" alt=\"Pyramids config\"/>"
      ],
      "metadata": {
        "id": "fqceIATXAgih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As an experimentation, you should also try to modify some other hyperparameters, Unity provides a very [good documentation explaining each of them here](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md).\n",
        "\n",
        "We’re now ready to train our agent 🔥."
      ],
      "metadata": {
        "id": "RI-5aPL7BWVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the agent\n",
        "\n",
        "The training will take 30 to 45min depending on your machine, go take a ☕️you deserve it 🤗."
      ],
      "metadata": {
        "id": "s5hr1rvIBdZH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fXi4-IaHBhqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927d785f-62c8-4656-fb04-dc089b4fc09b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            ┐  ╖\n",
            "        ╓╖╬│╡  ││╬╖╖\n",
            "    ╓╖╬│││││┘  ╬│││││╬╖\n",
            " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
            " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
            " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
            " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
            " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
            " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
            " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
            "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
            "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
            "          ╙╬╬╬╣╣╣╜\n",
            "             ╙\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 0.29.0.dev0,\n",
            "  ml-agents-envs: 0.29.0.dev0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 1.8.1+cu102\n",
            "[INFO] Connected to Unity environment with package version 2.2.1-exp.1 and communication version 1.5.0\n",
            "[INFO] Connected new brain: Pyramids?team=0\n",
            "2023-02-26 07:48:01.170519: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-26 07:48:04.411641: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-26 07:48:04.411975: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-26 07:48:04.412015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[INFO] Hyperparameters for behavior name Pyramids: \n",
            "\ttrainer_type:\tppo\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t512\n",
            "\t  buffer_size:\t409600\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.01\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  learning_rate_schedule:\tlinear\n",
            "\t  beta_schedule:\tlinear\n",
            "\t  epsilon_schedule:\tlinear\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t2\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\t  rnd:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t0.01\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t512\n",
            "\t      num_layers:\t3\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\t    learning_rate:\t0.0001\n",
            "\t    encoding_size:\tNone\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t5\n",
            "\tcheckpoint_interval:\t500000\n",
            "\tmax_steps:\t1000000\n",
            "\ttime_horizon:\t128\n",
            "\tsummary_freq:\t30000\n",
            "\tthreaded:\tFalse\n",
            "\tself_play:\tNone\n",
            "\tbehavioral_cloning:\tNone\n",
            "INFO:mlagents.trainers.stats:Hyperparameters for behavior name Pyramids: \n",
            "\ttrainer_type:\tppo\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t512\n",
            "\t  buffer_size:\t409600\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.01\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  learning_rate_schedule:\tlinear\n",
            "\t  beta_schedule:\tlinear\n",
            "\t  epsilon_schedule:\tlinear\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t2\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\t  rnd:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t0.01\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t512\n",
            "\t      num_layers:\t3\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\t    learning_rate:\t0.0001\n",
            "\t    encoding_size:\tNone\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t5\n",
            "\tcheckpoint_interval:\t500000\n",
            "\tmax_steps:\t1000000\n",
            "\ttime_horizon:\t128\n",
            "\tsummary_freq:\t30000\n",
            "\tthreaded:\tFalse\n",
            "\tself_play:\tNone\n",
            "\tbehavioral_cloning:\tNone\n",
            "[INFO] Pyramids. Step: 30000. Time Elapsed: 48.679 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 30000. Time Elapsed: 48.679 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 60000. Time Elapsed: 87.237 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 60000. Time Elapsed: 87.237 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 90000. Time Elapsed: 124.720 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 90000. Time Elapsed: 124.720 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 120000. Time Elapsed: 164.042 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 120000. Time Elapsed: 164.042 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 150000. Time Elapsed: 202.369 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 150000. Time Elapsed: 202.369 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 180000. Time Elapsed: 243.016 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 180000. Time Elapsed: 243.016 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 210000. Time Elapsed: 282.910 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 210000. Time Elapsed: 282.910 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 240000. Time Elapsed: 319.313 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 240000. Time Elapsed: 319.313 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 270000. Time Elapsed: 361.505 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 270000. Time Elapsed: 361.505 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 300000. Time Elapsed: 401.982 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 300000. Time Elapsed: 401.982 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 330000. Time Elapsed: 440.005 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 330000. Time Elapsed: 440.005 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 360000. Time Elapsed: 479.961 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 360000. Time Elapsed: 479.961 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 390000. Time Elapsed: 516.150 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 390000. Time Elapsed: 516.150 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 420000. Time Elapsed: 751.520 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 420000. Time Elapsed: 751.520 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 450000. Time Elapsed: 792.266 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 450000. Time Elapsed: 792.266 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 480000. Time Elapsed: 830.478 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 480000. Time Elapsed: 830.478 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Exported results/Pyramids Training/Pyramids/Pyramids-499968.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Pyramids Training/Pyramids/Pyramids-499968.onnx\n",
            "[INFO] Pyramids. Step: 510000. Time Elapsed: 872.349 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 510000. Time Elapsed: 872.349 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 540000. Time Elapsed: 912.568 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 540000. Time Elapsed: 912.568 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 570000. Time Elapsed: 954.366 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 570000. Time Elapsed: 954.366 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 600000. Time Elapsed: 993.312 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 600000. Time Elapsed: 993.312 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 630000. Time Elapsed: 1032.101 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 630000. Time Elapsed: 1032.101 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 660000. Time Elapsed: 1070.482 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 660000. Time Elapsed: 1070.482 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 690000. Time Elapsed: 1111.261 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 690000. Time Elapsed: 1111.261 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 720000. Time Elapsed: 1151.381 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 720000. Time Elapsed: 1151.381 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 750000. Time Elapsed: 1187.523 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 750000. Time Elapsed: 1187.523 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 780000. Time Elapsed: 1227.377 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 780000. Time Elapsed: 1227.377 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 810000. Time Elapsed: 1266.893 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 810000. Time Elapsed: 1266.893 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 840000. Time Elapsed: 1496.326 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 840000. Time Elapsed: 1496.326 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 870000. Time Elapsed: 1536.172 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 870000. Time Elapsed: 1536.172 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 900000. Time Elapsed: 1574.953 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 900000. Time Elapsed: 1574.953 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 930000. Time Elapsed: 1616.069 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 930000. Time Elapsed: 1616.069 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 960000. Time Elapsed: 1652.526 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 960000. Time Elapsed: 1652.526 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 990000. Time Elapsed: 1695.988 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 990000. Time Elapsed: 1695.988 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Exported results/Pyramids Training/Pyramids/Pyramids-999936.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Pyramids Training/Pyramids/Pyramids-999936.onnx\n",
            "[INFO] Exported results/Pyramids Training/Pyramids/Pyramids-1000192.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Pyramids Training/Pyramids/Pyramids-1000192.onnx\n",
            "[INFO] Copied results/Pyramids Training/Pyramids/Pyramids-1000192.onnx to results/Pyramids Training/Pyramids.onnx.\n",
            "INFO:mlagents.trainers.model_saver.torch_model_saver:Copied results/Pyramids Training/Pyramids/Pyramids-1000192.onnx to results/Pyramids Training/Pyramids.onnx.\n"
          ]
        }
      ],
      "source": [
        "!mlagents-learn ./config/ppo/PyramidsRND.yaml --env=./training-envs-executables/linux/Pyramids/Pyramids --run-id=\"Pyramids Training\" --no-graphics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txonKxuSByut"
      },
      "source": [
        "### Push the agent to the 🤗 Hub\n",
        "\n",
        "- Now that we trained our agent, we’re **ready to push it to the Hub to be able to visualize it playing on your browser🔥.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-push-to-hf --run-id=\"PyramidsRND\" --local-dir=\"./results/Pyramids Training\" --repo-id=\"Ryukijano/RND-Pyramid1mill\" --commit-message=\"First Push\""
      ],
      "metadata": {
        "id": "JZ53caJ99sX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e539c2b4-95c3-4057-9911-c9f4f5aacdad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyramidsRND\n",
            "Ryukijano/RND-Pyramid1mill\n",
            "This function will create a model card and upload your PyramidsRND into HuggingFace Hub. This is a work in progress: If you encounter a bug, please send open an issue\n",
            "REPO NAME:  RND-Pyramid1mill\n",
            "ORGANIZATION:  Ryukijano\n",
            "Cloning https://huggingface.co/Ryukijano/RND-Pyramid1mill into local empty directory.\n",
            "Download file Pyramids/events.out.tfevents.1677335036.ac74cbd175f7.14704.0: 100% 73.6k/73.6k [00:01<00:00, 58.4kB/s]\n",
            "Upload file Pyramids/Pyramids-1000192.pt:   0% 32.0k/12.8M [00:00<?, ?B/s]\n",
            "Upload file Pyramids/Pyramids-999936.pt:   0% 32.0k/12.8M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Upload file Pyramids/events.out.tfevents.1677397686.65630e9c7659.2018.0: 100% 21.2k/21.2k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Upload file Pyramids/Pyramids-499968.pt:   0% 32.0k/12.8M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload file Pyramids/Pyramids-499968.onnx:   2% 32.0k/1.35M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file Pyramids/Pyramids-1000192.pt:   4% 512k/12.8M [00:01<00:26, 491kB/s]\n",
            "Upload file Pyramids/Pyramids-999936.pt:   1% 160k/12.8M [00:01<01:41, 131kB/s]\u001b[A\n",
            "\n",
            "\n",
            "Upload file Pyramids/Pyramids-499968.pt:   1% 160k/12.8M [00:01<01:41, 131kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload file Pyramids/Pyramids-499968.onnx:  12% 160k/1.35M [00:01<00:09, 131kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file Pyramids.onnx:  12% 160k/1.35M [00:01<00:09, 131kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Upload file Pyramids/Pyramids-1000192.pt:  41% 5.28M/12.8M [00:02<00:02, 3.14MB/s]\n",
            "\n",
            "\n",
            "Upload file Pyramids/Pyramids-499968.pt:  31% 3.91M/12.8M [00:02<00:03, 2.36MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Upload file Pyramids/Pyramids-1000192.pt:  79% 10.1M/12.8M [00:03<00:00, 4.02MB/s]\n",
            "Upload file Pyramids/Pyramids-999936.pt:  67% 8.62M/12.8M [00:03<00:01, 3.56MB/s]\u001b[Aremote: Scanning LFS files for validity...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Ryukijano/RND-Pyramid1mill\n",
            "   326e03a..718a8f6  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:remote: Scanning LFS files for validity...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/Ryukijano/RND-Pyramid1mill\n",
            "   326e03a..718a8f6  main -> main\n",
            "\n",
            "Upload file Pyramids/Pyramids-1000192.pt: 100% 12.8M/12.8M [00:05<00:00, 2.67MB/s]\n",
            "\n",
            "Upload file Pyramids/Pyramids-999936.pt: 100% 12.8M/12.8M [00:05<00:00, 2.78MB/s]\u001b[A\n",
            "Upload file Pyramids/Pyramids-999936.pt: 100% 12.8M/12.8M [00:05<00:00, 2.67MB/s]\n",
            "\n",
            "\n",
            "Upload file Pyramids/events.out.tfevents.1677397686.65630e9c7659.2018.0: 100% 21.2k/21.2k [00:05<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "Upload file Pyramids/events.out.tfevents.1677397686.65630e9c7659.2018.0: 100% 21.2k/21.2k [00:05<?, ?B/s]\n",
            "\n",
            "\n",
            "\n",
            "Upload file Pyramids/Pyramids-499968.pt: 100% 12.8M/12.8M [00:05<00:00, 2.76MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Upload file Pyramids/Pyramids-499968.pt: 100% 12.8M/12.8M [00:05<00:00, 2.67MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file Pyramids/Pyramids-499968.onnx: 100% 1.35M/1.35M [00:05<00:00, 286kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload file Pyramids/Pyramids-499968.onnx: 100% 1.35M/1.35M [00:05<00:00, 276kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file Pyramids.onnx: 100% 1.35M/1.35M [00:05<00:00, 286kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload file Pyramids.onnx: 100% 1.35M/1.35M [00:05<00:00, 276kB/s]\n",
            "\n",
            " Your model is pushed to the hub. You can view your model here: https://huggingface.co/Ryukijano/RND-Pyramid1mill\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c-C72nMCzTEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "                           "
      ],
      "metadata": {
        "id": "yiEQbv7rB4mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Watch your agent playing 👀\n",
        "\n",
        "The temporary link for Pyramids demo is: https://singularite.itch.io/pyramids"
      ],
      "metadata": {
        "id": "7aZfgxo-CDeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🎁 Bonus: Why not train on another environment?\n",
        "Now that you know how to train an agent using MLAgents, **why not try another environment?** \n",
        "\n",
        "MLAgents provides 18 different and we’re building some custom ones. The best way to learn is to try things of your own, have fun.\n",
        "\n"
      ],
      "metadata": {
        "id": "hGG_oq2n0wjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cover](https://miro.medium.com/max/1400/0*xERdThTRRM2k_U9f.png)"
      ],
      "metadata": {
        "id": "KSAkJxSr0z6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have the full list of the one currently available on Hugging Face here 👉 https://github.com/huggingface/ml-agents#the-environments\n",
        "\n",
        "For the demos to visualize your agent, the temporary link is: https://singularite.itch.io (temporary because we'll also put the demos on Hugging Face Space)\n",
        "\n",
        "For now we have integrated: \n",
        "- [Worm](https://singularite.itch.io/worm) demo where you teach a **worm to crawl**.\n",
        "- [Walker](https://singularite.itch.io/walker) demo where you teach an agent **to walk towards a goal**.\n",
        "\n",
        "If you want new demos to be added, please open an issue: https://github.com/huggingface/deep-rl-class 🤗"
      ],
      "metadata": {
        "id": "YiyF4FX-04JB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "That’s all for today. Congrats on finishing this tutorial!\n",
        "\n",
        "The best way to learn is to practice and try stuff. Why not try another environment? ML-Agents has 18 different environments, but you can also create your own? Check the documentation and have fun!\n",
        "\n",
        "See you on Unit 6 🔥,\n",
        "\n",
        "## Keep Learning, Stay  awesome 🤗"
      ],
      "metadata": {
        "id": "PI6dPWmh064H"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b41fa3e4f1704166a2418f2c8ef0bc6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f718196e242a4648bdccf4080024ff69",
              "IPY_MODEL_8e7c289afa6b492aa0f05b9c01e4c596",
              "IPY_MODEL_960e7acc7aac4b58a9b9979a38001e6d",
              "IPY_MODEL_f113bad6ac9a470aa4538197b8933245",
              "IPY_MODEL_25df7f2224aa4499a217c54d72da606e"
            ],
            "layout": "IPY_MODEL_b07921d954f440bfa0710286b0ca84ac"
          }
        },
        "f718196e242a4648bdccf4080024ff69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb89755e2f741c19effa090b0ca9a92",
            "placeholder": "​",
            "style": "IPY_MODEL_06e92b3251bc41af9642a427752e9b0c",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "8e7c289afa6b492aa0f05b9c01e4c596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f53eaab2827348ccb8ee0bddc2f5d0a3",
            "placeholder": "​",
            "style": "IPY_MODEL_1fa0a6d36d63400cb24d520791285888",
            "value": ""
          }
        },
        "960e7acc7aac4b58a9b9979a38001e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_9bf362f578d34421ba4294119e26d162",
            "style": "IPY_MODEL_23c9d967006b460a864e53f0068fde1c",
            "value": true
          }
        },
        "f113bad6ac9a470aa4538197b8933245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d4ace146c29e4fe0ad8ab1fa747dddb0",
            "style": "IPY_MODEL_3d2ade4ac3cf441aa5b11c207d40d433",
            "tooltip": ""
          }
        },
        "25df7f2224aa4499a217c54d72da606e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b874a4b90e614c58b7ef88d28bc1ac1a",
            "placeholder": "​",
            "style": "IPY_MODEL_1fe698303e3f4d548dfe7d501e2aa0a7",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "b07921d954f440bfa0710286b0ca84ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "6cb89755e2f741c19effa090b0ca9a92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06e92b3251bc41af9642a427752e9b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f53eaab2827348ccb8ee0bddc2f5d0a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa0a6d36d63400cb24d520791285888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bf362f578d34421ba4294119e26d162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c9d967006b460a864e53f0068fde1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4ace146c29e4fe0ad8ab1fa747dddb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d2ade4ac3cf441aa5b11c207d40d433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "b874a4b90e614c58b7ef88d28bc1ac1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fe698303e3f4d548dfe7d501e2aa0a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}